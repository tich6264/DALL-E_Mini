{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd48218e3a06464fa7d3d71b329594da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff602737283d4e378e30a5d328f3e4e6",
              "IPY_MODEL_57b069b76f4441d7a855e4d176f39db6",
              "IPY_MODEL_978eb6cb02c84d97a60fbd1d2ba3f313"
            ],
            "layout": "IPY_MODEL_4e85d40aae644800a8ac6b26cd652390"
          }
        },
        "ff602737283d4e378e30a5d328f3e4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6a082b3d747109e3e56ff0e958c53",
            "placeholder": "​",
            "style": "IPY_MODEL_97c6c6dab4f74f289cce25030e676c48",
            "value": "Downloading: 100%"
          }
        },
        "57b069b76f4441d7a855e4d176f39db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9597251da4c540c08bf9e4d968f8d629",
            "max": 1329,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ffa8746683b431aa84f204d6d39cb41",
            "value": 1329
          }
        },
        "978eb6cb02c84d97a60fbd1d2ba3f313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2492446d8ea4e4b85f791657381a7bd",
            "placeholder": "​",
            "style": "IPY_MODEL_310dab52a24d4d9ba5d0cf13c6b3ebb4",
            "value": " 1.33k/1.33k [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "4e85d40aae644800a8ac6b26cd652390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f6a082b3d747109e3e56ff0e958c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c6c6dab4f74f289cce25030e676c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9597251da4c540c08bf9e4d968f8d629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffa8746683b431aa84f204d6d39cb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2492446d8ea4e4b85f791657381a7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310dab52a24d4d9ba5d0cf13c6b3ebb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DallE-Mini Text to Image Project\n",
        "\n",
        "This notebook will walk through the set up of dalle-mini, jax, etc. without using using cache requirements of hugging-face, weights, or bias. Thereby allowing you to run this application on any machine and generate images from given prompts under runtime support.\n"
      ],
      "metadata": {
        "id": "m6hK13awcHgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment set up and verification\n",
        "\n"
      ],
      "metadata": {
        "id": "a-kKRye-eJCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Set up"
      ],
      "metadata": {
        "id": "xbgYLz5SeYiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Jax"
      ],
      "metadata": {
        "id": "skxmpPWvc7CH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmJlJ7C4cPfT"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Google Colab select Runtime > Change Runtime Type> GPU. Validate if GPU is loaded properly"
      ],
      "metadata": {
        "id": "-zLRKws_c-uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jax.local_device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khbh3740dFCV",
        "outputId": "b0c1694c-e71d-4749-e428-41becb04c334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61k0rmiXdyuq",
        "outputId": "6171a914-9efa-4ed2-8c81-40c9a8f1b6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import all AI model components"
      ],
      "metadata": {
        "id": "jKUWIaYbefxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install DALLE-mini"
      ],
      "metadata": {
        "id": "_eTiKxdRezfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dalle-mini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrjQcSvgd6VB",
        "outputId": "9990205a-9559-4ead-92fc-db567318fd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 59.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 69.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 506 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 59.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 70.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 240 kB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 154 kB 65.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 28.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 68.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 68.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 57.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 74.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 67.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 71.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 67.3 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Jax's version of the VQGan"
      ],
      "metadata": {
        "id": "vAZgltWJe_wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPk8ULB0fJtz",
        "outputId": "d4bfd672-4496-48d0-e27f-65fc2b7bb2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for vqgan-jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all model components"
      ],
      "metadata": {
        "id": "P2HtAIiFfHtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dalle_mini import DalleBart, DalleBartProcessor\n",
        "#Jax binding for vqgan\n",
        "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
        "from transformers import CLIPProcessor, FlaxCLIPModel"
      ],
      "metadata": {
        "id": "WsFbFRmnfq20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Hugging Face Library - already installed on Google Colab"
      ],
      "metadata": {
        "id": "p-v6FFN4gYBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_url, cached_download, hf_hub_download"
      ],
      "metadata": {
        "id": "dmdHYfZffrQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download all DallE-mini files from hugging face.  \n",
        "Files are listed at the following link:"
      ],
      "metadata": {
        "id": "bFlajFGoh7De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/dalle-mini/dalle-mini/tree/main"
      ],
      "metadata": {
        "id": "aFQa7Wn3hWR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: All files will be saved locally.  Note: create new folders in google colab structure under content>dalle-mini>vqgan"
      ],
      "metadata": {
        "id": "p-arPTYolVKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "NcZZt_qFoQeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dalle_mini_file_list = ['config.json', 'enwiki-words-frequency.txt', \n",
        "                         'flax_model.msgpack', 'merges.txt', \n",
        "                         'special_tokens_map.json', 'tokenizer.json', \n",
        "                         'tokenizer_config.json', 'vocab.json']"
      ],
      "metadata": {
        "id": "po3aewmZin09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in dalle_mini_file_list:\n",
        "  # downloaded to local hugging face cache folder\n",
        "  downloaded_file = hf_hub_download('dalle-mini/dalle-mini', filename = file)\n",
        "  target_path = '/content/dalle-mini/' + file\n",
        "  # copies files from the cache folder to the local dalle-mini folder\n",
        "  # removes dependency on library cache - allows us to run anywhere\n",
        "  # (e.g. refernce from our API)\n",
        "  shutil.copy(downloaded_file, target_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378,
          "referenced_widgets": [
            "dd48218e3a06464fa7d3d71b329594da",
            "ff602737283d4e378e30a5d328f3e4e6",
            "57b069b76f4441d7a855e4d176f39db6",
            "978eb6cb02c84d97a60fbd1d2ba3f313",
            "4e85d40aae644800a8ac6b26cd652390",
            "21f6a082b3d747109e3e56ff0e958c53",
            "97c6c6dab4f74f289cce25030e676c48",
            "9597251da4c540c08bf9e4d968f8d629",
            "7ffa8746683b431aa84f204d6d39cb41",
            "d2492446d8ea4e4b85f791657381a7bd",
            "310dab52a24d4d9ba5d0cf13c6b3ebb4"
          ]
        },
        "id": "K2yVys_6i2F2",
        "outputId": "1302f6ba-4900-4c2c-f721-f2655b75a8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd48218e3a06464fa7d3d71b329594da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-85fda4eaaa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# removes dependency on library cache - allows us to run anywhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# (e.g. refernce from our API)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dalle-mini/config.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate files successfully downloaded and we are using local file versions (not symlinks - when loaded models, symlinks do not work)"
      ],
      "metadata": {
        "id": "iwy00mKHpevG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/dalle-mini"
      ],
      "metadata": {
        "id": "DEHaUfsSkIWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve all VQGAN files from hugging face\n",
        "Files are listed at the following link: \n",
        "\n",
        "https://huggingface.co/dalle-mini/vqgan_imagenet_f16_16384/tree/main"
      ],
      "metadata": {
        "id": "3hxxf43Wikk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vqgan_file_list = ['config.json', 'flax_model.msgpack']"
      ],
      "metadata": {
        "id": "w0aVyT5Wti5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in vqgan_file_list:\n",
        "  # downloaded to local hugging face cache folder\n",
        "  downloaded_file = hf_hub_download('dalle-mini/vqgan_imagenet_f16_16384', filename = file)\n",
        "  target_path = '/content/dalle-mini/vqgan/' + file\n",
        "  # copies files from the cache folder to the local dalle-mini folder\n",
        "  # removes dependency on library cache - allows us to run anywhere\n",
        "  # (e.g. refernce from our API)\n",
        "  shutil.copy(downloaded_file, target_path)"
      ],
      "metadata": {
        "id": "sW9mqTL4sax-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate files successfully downloaded and we are using local file versions"
      ],
      "metadata": {
        "id": "YQ5fNrkpt9ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/dalle-mini/vqgan"
      ],
      "metadata": {
        "id": "ZWhpVEJ4t-h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Models"
      ],
      "metadata": {
        "id": "rCftrDJnPY_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load DallE-mini model"
      ],
      "metadata": {
        "id": "8sVCoaV1u2Jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uses flax_model.msgpack and config.json files"
      ],
      "metadata": {
        "id": "hY66neraQWm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DALLE_MODEL_PATH = '/content/dalle-mini'\n",
        "DALLE_COMMIT_ID = None\n",
        "dalle_model, dalle_params = DalleBart.from_pretrained(\n",
        "    DALLE_MODEL_PATH, revision = DALLE_COMMIT_ID, dtype=jnp.float16, _do_init=False,\n",
        ")\n",
        "# ensure model is not initialized: _do_init"
      ],
      "metadata": {
        "id": "cXwCIdDCvQp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate DallE-mini Model"
      ],
      "metadata": {
        "id": "ycyhHVS6QNRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dalle_model"
      ],
      "metadata": {
        "id": "trESFYJFxpez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dalle_model.config"
      ],
      "metadata": {
        "id": "-iC-vpAKxyIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View model params - comment out to save space on jupyter notebook\n",
        "# dalle_params"
      ],
      "metadata": {
        "id": "p9jzj9J8x6c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load VQGAN Model"
      ],
      "metadata": {
        "id": "lXn8G6HMPnPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VQGAN_MODEL_PATH = '/content/dalle-mini/vqgan'\n",
        "VQGAN_COMMIT_ID = None\n",
        "vqgan_model, vqgan_params = VQModel.from_pretrained(\n",
        "    VQGAN_MODEL_PATH, revision = VQGAN_COMMIT_ID, dtype=jnp.float16, _do_init=False,\n",
        ")"
      ],
      "metadata": {
        "id": "rDVE4PXTy2z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate VQGAN Model"
      ],
      "metadata": {
        "id": "TN8EyZaiRRcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vqgan_model.config"
      ],
      "metadata": {
        "id": "ZoK2t8it0Pti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vqgan_params #comment out to save space on jupyter notebook"
      ],
      "metadata": {
        "id": "wOJFWkbkcLDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load DallE Bart Processor"
      ],
      "metadata": {
        "id": "_gwzss_YPu67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uses downloaded files related with tokenization"
      ],
      "metadata": {
        "id": "HECHmkoFQEqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the same paths as dalle-mini\n",
        "DALLE_MODEL_PATH = '/content/dalle-mini'\n",
        "DALLE_COMMIT_ID = None\n",
        "dalle_bart_processor = DalleBartProcessor.from_pretrained(\n",
        "    DALLE_MODEL_PATH, revision = DALLE_COMMIT_ID)\n",
        "\n"
      ],
      "metadata": {
        "id": "UKyE9BpLeQnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate DallE Bart Processor"
      ],
      "metadata": {
        "id": "8NUKVlmWRk-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dalle_bart_processor"
      ],
      "metadata": {
        "id": "ss4AcYw9xoGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-GPU Set-up"
      ],
      "metadata": {
        "id": "UNnU3JL_RpwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This set up is optional depending on what you have available to you. But a multi-GPU implementation is activated with replication.  Specifically, it will replicate parameters on all available devices.  \n",
        "\n",
        "Note: If ran on google collab, only one gpu is available."
      ],
      "metadata": {
        "id": "yI9_9brEQqRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax.jax_utils import replicate\n",
        "params = replicate(dalle_params)\n",
        "vqgan_params = replicate(vqgan_params)"
      ],
      "metadata": {
        "id": "MwOJBEUtz7XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference\n",
        "### Encode text to Images"
      ],
      "metadata": {
        "id": "5DxTfbXdVulr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use partial class to parallelize given functions"
      ],
      "metadata": {
        "id": "lCFGdbdgUjjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial"
      ],
      "metadata": {
        "id": "WP_UBIcdVxwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the main DallE-mini model to generate or  encode images i.e. pass in the tokenized prompt and encode them into images."
      ],
      "metadata": {
        "id": "O00OKdrbUifr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jax.pmap, axis_name=\"batch\", static_broadcasted_argnums =(3,4,5,6))\n",
        "def p_generate(tokenized_prompt, key, params, top_k, top_p, temperature, condition_scale):\n",
        "  return dalle_model.generate(\n",
        "      **tokenized_prompt, \n",
        "      prng_key=key,\n",
        "      params = params,\n",
        "      top_k = top_k,\n",
        "      top_p = top_p,\n",
        "      temperature = temperature,\n",
        "      condition_scale= condition_scale,\n",
        "  )"
      ],
      "metadata": {
        "id": "dQiNNMl8V1WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decode Images"
      ],
      "metadata": {
        "id": "TGFmt6-bXcom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jax.pmap, axis_name=\"batch\")\n",
        "def p_decode(indices, params):\n",
        "  return vqgan_model.decode_code(indices, params=params)\n"
      ],
      "metadata": {
        "id": "Ys2kfzjUnVTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise Encoder Decoder Pipeline\n",
        "\n",
        "Create example text input prompt"
      ],
      "metadata": {
        "id": "5ddjZ8VXoEkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ['vincent van gogh paintings mixed with pumpkins']\n",
        "# Process prompts with bart\n",
        "tokenized_prompts = dalle_bart_processor(prompt)"
      ],
      "metadata": {
        "id": "3robFH0mox7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribute tokenized prompts across multiple gpu devices"
      ],
      "metadata": {
        "id": "Z6ybJj6YYTfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_prompt = replicate(tokenized_prompts)\n",
        "print(tokenized_prompt)"
      ],
      "metadata": {
        "id": "xUq5YmF6pdIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Model Parameters"
      ],
      "metadata": {
        "id": "n5C2xlUTppKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Random Key Parameter"
      ],
      "metadata": {
        "id": "GgUnAGFJpwww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#create a random key\n",
        "seed = random.randint(0, 2**32 - 1)\n",
        "key = jax.random.PRNGKey(seed)"
      ],
      "metadata": {
        "id": "TpxWXtw4pyou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of predictions (images) per prompt\n",
        "num_predictions = 4"
      ],
      "metadata": {
        "id": "HSC8Om0ap9ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Customize Generation Paramaters\n",
        "* Resource: https://huggingface.co/blog/how-to-generate"
      ],
      "metadata": {
        "id": "P4egw9kjqgb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_top_k = None\n",
        "gen_top_p = None\n",
        "temperature = None\n",
        "#conditioning scale\n",
        "cond_scale = 10.0\n"
      ],
      "metadata": {
        "id": "Yy7LJDIDrxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Images"
      ],
      "metadata": {
        "id": "IPLEuPUNZXsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax.training.common_utils import shard_prng_key\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import trange"
      ],
      "metadata": {
        "id": "3xRYXTpnsgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prompts: {prompt}\")"
      ],
      "metadata": {
        "id": "hv6SWtsPszLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "#device count = 1\n",
        "for i in trange(max(num_predictions // jax.device_count(), 1)):\n",
        "  # generate a new key\n",
        "  key, subkey = jax.random.split(key)\n",
        "\n",
        "  # Encoder\n",
        "  # generate images \n",
        "  encoded_images = p_generate(\n",
        "      tokenized_prompt,\n",
        "      shard_prng_key(subkey),\n",
        "      params,\n",
        "      gen_top_k,\n",
        "      gen_top_p,\n",
        "      temperature,\n",
        "      cond_scale,\n",
        "  )\n",
        "\n",
        "  # remove beginning of sequence\n",
        "  encoded_images = encoded_images.sequences[..., 1:]\n",
        "\n",
        "  # Decoder\n",
        "  # decode images\n",
        "  decoded_images = p_decode(encoded_images, vqgan_params)\n",
        "\n",
        "  # Clip method - select top images\n",
        "  decoded_images = decoded_images.clip(0.0, 1.0).reshape((-1,256, 256,3))\n",
        "\n",
        "  # convert images to numpy array in order to display the images\n",
        "  for decoded_img in decoded_images:\n",
        "    img = Image.fromarray(np.asarray(decoded_img * 255, dtype = np.uint8))\n",
        "    images.append(img)\n",
        "    display(img)\n",
        "    print()\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "oPv5Ow9atMNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If running into errors in the above cell, ensure runtime environment is reset to use GPU (not TPU or CPU).  This may reuire rerunning all code blocks in the notebook\n",
        "\n",
        "Check runtime environment"
      ],
      "metadata": {
        "id": "Q1vohS_14LBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "E_v5lEBY4FXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: https://www.youtube.com/watch?v=uVYZR6Wab7o"
      ],
      "metadata": {
        "id": "V779ssXTf2PQ"
      }
    }
  ]
}